{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only z is quantized\n",
    "# for f0 and ld different heads in the rnn is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4PsmoYNMWir_",
    "outputId": "89a0cd45-7dd1-4caf-e23a-3e7549775576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Functional-api-RNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(32, None, 18)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (32, None, 512)      1087488     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (32, None, 512)      2099200     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (32, None, 512)      2099200     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (32, None, 1998)     1024974     lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, None, 121)      62073       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (32, None, 64)       32832       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,405,767\n",
      "Trainable params: 6,405,767\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.util_funcs import generate_audio, generate_sample_test\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "#load latent space\n",
    "batch_size = 32\n",
    "\n",
    "latent_files_path = 'vq-50k-latent_space'\n",
    "\n",
    "training_code_inds = np.load('saved_latent_spaces/{}/train_code_inds.npy'.format(latent_files_path))\n",
    "training_codes = np.load('saved_latent_spaces/{}/train_codes.npy'.format(latent_files_path))\n",
    "codebook = np.load('saved_latent_spaces/{}/codebook.npy'.format(latent_files_path))\n",
    "\n",
    "code_data = tf.data.Dataset.from_tensor_slices((training_code_inds, training_codes))\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "code_data = code_data.cache()\n",
    "code_data_ready = code_data.shuffle(50000).batch(batch_size, drop_remainder=True)#.repeat()\n",
    "\n",
    "seqlen = 1000\n",
    "dim_code = codebook.shape[-1] + 1 + 1\n",
    "\n",
    "inputs = tfkl.Input(batch_shape=(batch_size, None, dim_code))\n",
    "x = tfkl.LSTM(512, return_sequences=True, stateful=True)(inputs)\n",
    "x = tfkl.LSTM(512, return_sequences=True, stateful=True)(x)\n",
    "x = tfkl.LSTM(512, return_sequences=True, stateful=True)(x)\n",
    "\n",
    "f0_output = tfkl.Dense(1998)(x)\n",
    "ld_output = tfkl.Dense(121)(x)\n",
    "z_output = tfkl.Dense(codebook.shape[0])(x)\n",
    "    \n",
    "model_rnn = tf.keras.Model(inputs=inputs, outputs=[f0_output, ld_output, z_output], name='Functional-api-RNN')\n",
    "\n",
    "EPOCHS = 20\n",
    "train_steps = 200000\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "lr = tf.optimizers.schedules.PolynomialDecay(0.000001, train_steps, 0.000000001)\n",
    "opt = tf.optimizers.Adam(lr)\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"saved_models/lstm\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model_rnn,\n",
    "                           optimizer=opt)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.5185\n",
      "Epoch 1 Batch 100 Loss 5.5115\n",
      "Epoch 1 Batch 200 Loss 5.5038\n",
      "Epoch 1 Batch 300 Loss 5.4904\n",
      "Epoch 1 Batch 400 Loss 5.4726\n",
      "Epoch 1 Batch 500 Loss 5.4364\n",
      "Epoch 1 Batch 600 Loss 5.3217\n",
      "Epoch 1 Batch 700 Loss 5.1298\n",
      "Epoch 1 Batch 800 Loss 5.1427\n",
      "Epoch 1 Batch 900 Loss 4.9406\n",
      "Epoch 1 Batch 1000 Loss 4.8899\n",
      "Epoch 1 Batch 1100 Loss 4.9016\n",
      "Epoch 1 Batch 1200 Loss 4.8412\n",
      "Epoch 1 Loss 4.8863\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be1a621a1129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {} Loss {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sample_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mgen_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_random\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/ratul/oktoberfest/utils/util_funcs.py\u001b[0m in \u001b[0;36mgenerate_sample_test\u001b[0;34m(model_rnn, code, chunk_len, seqlen)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_sample_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0_scaleds_to_f0_hzs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/ratul/oktoberfest/utils/util_funcs.py\u001b[0m in \u001b[0;36msample_test\u001b[0;34m(model_rnn, codes, chunk_len, seqlen)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mgen_f0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mgen_f0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0_hzs_to_f0_scaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_f0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mgen_f0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_f0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfd' is not defined"
     ]
    }
   ],
   "source": [
    "# @tf.function\n",
    "def train(ind_batch, code_batch):\n",
    "    targets_f0 = ind_batch[:, 1:, 0:1] \n",
    "    targets_f0 = tf.reshape(targets_f0, [-1,seqlen-1])\n",
    "    targets_ld = ind_batch[:, 1:, 1:2] \n",
    "    targets_ld = tf.reshape(targets_ld, [-1,seqlen-1]) * (-1)\n",
    "    targets_z = ind_batch[:, 1:, 2:]\n",
    "    targets_z = tf.reshape(targets_z, [-1,seqlen-1])\n",
    "    inp = code_batch[:, :-1]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        out = model_rnn(inp)\n",
    "        xent_f0 = loss(targets_f0, out[0])\n",
    "        xent_ld = loss(targets_ld, out[1])\n",
    "        xent_z = loss(targets_z, out[2])\n",
    "        xent = (xent_f0 + xent_ld + xent_z) / 3.\n",
    "    grads = tape.gradient(xent, model_rnn.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model_rnn.trainable_variables))\n",
    "\n",
    "    return xent, out\n",
    "\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    for batch, (inds, codes) in enumerate(code_data_ready):\n",
    "        model_rnn.reset_states()\n",
    "        xent, out = train(inds, codes)\n",
    "        losses.append(xent)\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                 epoch + 1, batch, xent))\n",
    "            \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, xent))\n",
    "    gen = generate_sample_test(model_rnn, codes, chunk_len=1, seqlen=1)\n",
    "    gen_random = generate_audio(model_rnn)\n",
    "    ipd.display(Audio(gen_random[0],rate=16000))\n",
    "    ipd.display(Audio(gen[0],rate=16000))\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vqvae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
